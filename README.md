# zbMATH Open Knowledge Graph

We present a domain-specific knowledge graph (KG) derived from [**zbMATH Open**](https://zbmath.org/), the worldâ€™s most comprehensive and historically deep mathematical database, covering scholarly work from 1763 to the present. 

Unlike general-purpose scholarly KGs that rely primarily on citation networks, our approach leverages the unique features of zbMATH: expert-curated reviews, high-quality author disambiguation, and expert-assigned keywords and *Mathematics Subject Classification* (MSC), a fine-grained and historically stable ontology of mathematical subjects. This combination provides a rich semantic foundation for capturing the long-term evolution of mathematical knowledge. The resulting zbMATH KG, fully compliant with RDF and Semantic Web standards, interconnects publications, reviews, classifications, and related entities, allowing advanced retrieval and reasoning beyond conventional bibliometric methods.

We demonstrate through case studies how the graph:
- *(i)* uncovers **overlooked precursors** beyond citation,
- *(ii)* reveals **conceptual ancestry across fields**,
- *(iii)* traces **concept revivals** in new contexts, and
- *(iv)* maps **authorâ€“reviewer intellectual lineage**, showing how ideas propagate via scholarly interactions.

These **historically grounded retrieval** methods expose intellectual dynamics that conventional citation- or keyword-based systems fail to capture.

## ğŸ“Š Statistics

- **Publications**: 4.5M+
- **Authors**: 1.2M+
- **Reviews**: 3.8M+
- **Subject Classifications (MSC)**: 5,000+
- **Triples**: 80M+

## ğŸ“ Repository Structure

- [`data/`](./data) â€“ `.jsonl` raw data and `.ttl` RDF KG (subset), ontology files (`.ttl`), etc.
- [`front/`](./front) â€“ Fuseki triple store setup for serving the RDF subset (example only â€” production SPARQL endpoint runs on Virtuoso for scalability)
- [`src/`](./src) â€“ Source code for data harvest, RDF KG construction, statistics calculation, etc.
- [`use-case/`](./use-case) â€“ Use case-specific code, SPARQL queries, results, and visualizations
- [`run-convert.sh`](./run-convert.sh) â€“ Shell script to convert raw data into RDF format
- [`README.md`](./README.md) â€“ Project documentation


## ğŸ“Œ Key Features

- ğŸ§  **RDF-Based Knowledge Representation**  
  All entities and relationships are modeled as RDF triples, supporting semantic interoperability and Linked Open Data standards.

- ğŸ” **SPARQL Endpoint**  
  Query the knowledge graph using SPARQL to retrieve complex and semantically rich information.

- ğŸ“š **Curated Mathematical Metadata**  
  Includes publications, authors, expert-curated reviews, keywords, MSC classifications, and citation networks.

- ğŸ”„ **Linked Data Integration**  
  Cross-referenced with external datasets (e.g., ORCID, Wikidata) to enhance entity resolution and connectivity.

## ğŸ—ï¸ Knowledge Graph Construction

### ğŸ”§ Prerequisites

Ensure the following are installed:

- Python 3.8+
- Java 8+ (for RDF libraries Apache Jena)
- RDF triple store. Here we use [Apache Jena Fuseki](https://jena.apache.org/documentation/fuseki2/) as example for its simplicity, (example only â€” production SPARQL endpoint runs on Virtuoso for scalability)
- `pip` for Python dependency management

### ğŸ› ï¸ Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/your-username/zbmath-open-knowledge-graph.git
cd zbmath-open-knowledge-graph
pip install -r requirements.txt
```

### ğŸ“œ License

All content generated by zbMATH Open KG are distributed under [CC-BY-SA 4.0.](https://creativecommons.org/licenses/by-sa/4.0/)

ğŸ“§ Contact: author@anonymous.org
